











import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

np.random.seed(2030)

# Sample data
sample1 = np.random.multivariate_normal(
    mean=np.array([2, 0]),
    cov=np.array([[2, 0], [0, 2]]),
    size=300
)

sample2 = np.random.multivariate_normal(
    mean=np.array([-1, 4]),
    cov=np.array([[2, 0.5], [0.5, 1]]),
    size=180
)

sample3 = np.random.multivariate_normal(
    mean=np.array([-3, -2]),
    cov=np.array([[1, -0.2], [-0.2, 2]]),
    size=120
)

# Generates a dataset with data sampled from 3 normal distributions.
data = np.concatenate((sample1, sample2, sample3), axis=0)
initial_representatives = [[5, 0], [4.5, 0], [4, 0]]

# Define RGB colors for the clusters.
colors = np.array([
    [1, 0, 0], 
    [0, 1, 0], 
    [0, 0, 1]  
])

fig, axes = plt.subplots(5, 1, figsize=(20, 20))

# For demonstration purposes, we will purposely limit the number of k-means iterations
# and show you the outputs along the way!
num_iterations = [1, 2, 6]
for i in range(len(num_iterations)):
    kmeans = KMeans(n_clusters=3, random_state=0, init=initial_representatives, max_iter=num_iterations[i]).fit(data)

    ax = axes[i]
    ax.scatter(data[:, 0], data[:, 1], c=colors[kmeans.labels_], s=5)
    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', c='black', s=100)
    ax.set_title(f'K-Means with {num_iterations[i]} Iterations')
    ax.set_aspect('equal')
    ax.set_xticks([])
    ax.set_yticks([])

# Now, we allow the algorithm to run until convergence and plot the clusters.
kmeans = KMeans(n_clusters=3, random_state=0, init=initial_representatives).fit(data)

ax = axes[3]
ax.scatter(data[:, 0], data[:, 1], c=colors[kmeans.labels_], s=5)
ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', c='black', s=100)
ax.set_title(f'Final Clustering')
ax.set_aspect('equal')
ax.set_xticks([])
ax.set_yticks([])

# We also run the code again for a bunch of different iteration numbers, and plot the 
# rate of convergence to the solution.
costs = []
for i in range(kmeans.n_iter_):
    kmeans = KMeans(n_clusters=3, random_state=0, init=initial_representatives, max_iter=i+1).fit(data)
    costs.append(kmeans.inertia_ / data.shape[0])

ax = axes[4]
ax.plot(range(1, kmeans.n_iter_ + 1), costs, marker='o', linestyle='-', color='b')
ax.set_title('Rate of Convergence of K-means')
ax.set_xlabel('Iteration')
ax.set_ylabel('Cost (Mean Squared Distance)')
ax.set_aspect('equal')
ax.set_xticks(range(1, kmeans.n_iter_ + 1))
ax.set_yticks([])

plt.tight_layout()
plt.show()



