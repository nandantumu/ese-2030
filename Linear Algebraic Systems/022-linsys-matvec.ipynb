{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7554ca-5ac4-4958-b713-648e3fd54114",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: Matrices and Vectors\n",
    "subject:  Linear Algebraic Systems\n",
    "subtitle: The building blocks of linear algebra\n",
    "short_title: Matrices and Vectors\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: matrices, vectors, matrix arithmetic, matrix multiplication\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca8556-3e7f-4f1c-b466-04f0e14b12e5",
   "metadata": {},
   "source": [
    "## Reading\n",
    "Material related to this page, as well as additional exercises, can be found in ALA Ch. 1.2, LAA Ch 2.1, and ILA Ch. 2.4.  These notes are mostly based on ALA Ch 1.2 and LAA Ch 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170438e7",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- what matrices and vectors are\n",
    "- what arithmetic operations are allowed when working with matrices and vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6aeff-4ad9-42b7-9fb4-a82ada3e07b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Matrices and Vectors\n",
    "A _matrix_ is a rectangular array of numbers.  For example\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix} 1 & 0 & 3 \\\\ -2 & 4 & 1 \\end{bmatrix}, \\quad \\begin{bmatrix} \\pi & 0 \\\\ e & \\frac{1}{2} \\\\ -1 & 0.83 \\\\ \\sqrt{5} & -\\frac{4}{7} \\end{bmatrix}, \\quad \\begin{bmatrix} 0 & 0 & 0 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "are all examples of matrices.  We use the notation\n",
    "\\begin{equation}\n",
    "\\label{matrix}\n",
    "A = \n",
    "\\begin{bmatrix} \n",
    "a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "for a generic matrix $A$ of size $m \\times n$ (read \"$m$ by $n$\"), where $m$ denotes the number of _rows_ in $A$ and $n$ denotes the number of _columns_[^cols].  Therefore, the preceding examples of matrices have respective sizes $2 \\times 3$, $4 \\times 2$, and $1 \\times 3$.  A matrix is _square_ if $m=n$, i.e., it has the same number of rows as columns.  A _column vector_ is an $m \\times 1$ matrix, while a _row vector_ is a $1 \\times n$ matrix.  While these might seem like they are the same thing, they very much are not!  Column vectors end up playing a much more important role in our story, and so whenever we just say \"vector\" we will always mean a column vector.  A $1 \\times 1$ matrix, which has a single entry, is both a column and row vector, and as we'll see later, behaves like an ordinary number.\n",
    "\n",
    "The number that lies in the $i$th row and $j$th column of $A$ is called the $(i,j)$ _entry_ of $A$, and is denoted by $a_{ij}$.  The row index always appears first and the column index second.  Each column of $A$ is a $m \\times 1$ vector, which we denote by $\\vv a_1, \\dots \\vv a_n$. It will often be convenient to write a matrix in terms of its columns:\n",
    "```{math}\n",
    ":label: colmat\n",
    "A = \\begin{bmatrix} \\vv a_1 & \\vv a_2 & \\cdots & \\vv a_n \\end{bmatrix}\n",
    "```\n",
    "```{note}\n",
    "We will consistently use bold face lower case letters to denote vectors, and ordinary capital letters to denote matrices.\n",
    "```\n",
    "[^cols]: It is not a coincidence that $n$ is also the letter that we used for the number of unknowns in a [linear equation](./021-linsys-gauss.ipynb#lin-eq)! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b6368-db39-46ab-a675-f055e405179e",
   "metadata": {},
   "source": [
    "### Worked Examples\n",
    "````{exercise}  TODO: Exercise 1\n",
    ":label: row-reduce-ex1\n",
    "Write me\n",
    ":::{hint} Click me for a hint!\n",
    ":class: dropdown\n",
    "Write me\n",
    "\n",
    ":::\n",
    "```{solution} my-exercise\n",
    ":class: dropdown\n",
    "Write me\n",
    "```\n",
    "````\n",
    "\n",
    "````{exercise}  TODO: Exercise 1\n",
    ":label: row-reduce-ex1\n",
    "Write me\n",
    ":::{hint} Click me for a hint!\n",
    ":class: dropdown\n",
    "Write me\n",
    "\n",
    ":::\n",
    "```{solution} my-exercise\n",
    ":class: dropdown\n",
    "Write me\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5132587-59ce-487e-8352-86e812944156",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Linear Systems in Matrix-Vector Notation\n",
    "A general linear system of $m$ equations in $n$ unknowns takes the form\n",
    "\\begin{equation}\n",
    "\\label{gen-linsys}\n",
    "\\begin{array}{cccl}\n",
    "a_{11} x_1 + a_{12} x_2 +& \\cdots &+ a_{1n} x_n  = & b_1,\\\\\n",
    "a_{21} x_1 + a_{22} x_2 +& \\cdots &+ a_{2n} x_n  = & b_2,\\\\\n",
    "\\vdots & \\vdots && \\vdots \\\\\n",
    "a_{m1} x_1 + a_{m2} x_2 +& \\cdots &+ a_{mn} x_n  = & b_m,\\\\\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "which we rewrite compactly as\n",
    "```{math}\n",
    ":label: matvec-eq\n",
    "A \\vv x = \\vv b.\n",
    "```\n",
    "Equation [](#matvec-eq) is composed of three basic ingredients: the $m \\times n$ _coefficient matrix_ $A$, with entries $a_{ij}$ as in [](#matrix), the column vector $\\vv x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\\end{bmatrix}$ containing the _unknowns_ or _variables_ and the column vector $\\vv b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{bmatrix}$ containing the _right-hand sides_.  As you can see, it is a bit unwieldy to write column vectors inline, and so we will often equivalently write them as $\\vv x = (x_1, x_2, \\cdots, x_n)$ and $\\vv b = (b_1, b_2, \\cdots, b_m)$ instead.\n",
    "\n",
    "```{warning}\n",
    "Both $(1,2,3)$ and $\\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ represent the same $3 \\times 1$ column vector.  However, $\\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix}$ is a _different_ $1 \\times 3$ row vector!  $(1,2,3)$ is understood to be a column vector because of the round brackets and the commas, whereas $\\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix}$ is understood to be a row vector because of the square brackets and no commas.  It's a bit tricky, but you'll get used to it in no time!\n",
    "```\n",
    "\n",
    "Revisiting linear system [](./021-linsys-gauss.ipynb#simple-linsys), we see that the coefficient matrix $A$, the unknown vector $\\vv x$, and the right hand side vector $\\vv b$ can be read off as\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & 2 & 1 \\\\\n",
    "2 & 6 & 1 \\\\\n",
    "1 & 1 & 4 \\end{bmatrix}, \\quad \\vv x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}, \\quad \\vv b = \\begin{bmatrix} 2 \\\\ 7 \\\\ 3 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Note that if a variable doesn't appear in an equation, then the corresponding matrix entry is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8525c0cb-a973-4e86-8d3b-b77ea2c1235b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Worked examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceffd52-56eb-4625-8fbc-e4696a69e3f4",
   "metadata": {},
   "source": [
    "````{exercise}  TODO\n",
    ":label: row-reduce-ex1\n",
    "Write me\n",
    ":::{hint} Click me for a hint!\n",
    ":class: dropdown\n",
    "Write me\n",
    "\n",
    ":::\n",
    "```{solution} my-exercise\n",
    ":class: dropdown\n",
    "Write me\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6493b5-6b12-415a-a159-646579661219",
   "metadata": {},
   "source": [
    "````{exercise}  TODO\n",
    ":label: row-reduce-ex1\n",
    "Write me\n",
    ":::{hint} Click me for a hint!\n",
    ":class: dropdown\n",
    "Write me\n",
    "\n",
    ":::\n",
    "```{solution} my-exercise\n",
    ":class: dropdown\n",
    "Write me\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b067c-cc53-48ca-8792-103f7ecf485a",
   "metadata": {},
   "source": [
    "## Matrix Arithmetic\n",
    "\n",
    "Matrix arithmetic involves three basic operations: _matrix addition_, _scalar multiplication_, and _matrix multiplication_. \n",
    "\n",
    "### Matrix Addition\n",
    "First we define _addition_ of matrices.  You are allowed to add two matrices only if they are of the _same size_, and matrix addition is performed entry-wise.  For example\n",
    "$$\n",
    "\\bm 1 & 2 \\\\ -1 & 0\\em + \\bm 3 & -5 \\\\ 2 & 1 \\em = \\bm 4 & -3 \\\\ 1 & 1 \\em.\n",
    "$$\n",
    "More generally, if $A$ and $B$ are $m \\times n$ matrices, then their sum $C = A+ B$ is the $m \\times n$ matrix whose entries are given by $c_{ij} = a_{ij} + b_{ij}$ for $i=1,\\dots,m$ and $j=1,\\dots,n$.  When defined, matrix addition behaves just like ordinary addition.  It is commutative, so $A + B = B + A$, and associative, so $A + (B + C) = (A+ B) + C = A + B + C$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9db14-cb47-4734-89f6-51c613d04667",
   "metadata": {},
   "source": [
    "### Scalar multiplication\n",
    "A _scalar_ is a fancy name for an ordinary number.  For now, we restrict ourselves to scalars, vectors, and matrices with _real_ entries, but we will eventually extend these ideas to complex numbers and matrices with complex entries.  Although technically not the same thing, we will treat the $1 \\times 1$ matrix $[c]$ and the scalar $c \\in \\R$ as a scalar,[^notation] that is to say as an ordinary number, so we will drop the brackets. _Scalar multiplication_ takes a scalar $c$ and an $m \\times n$ matrix $A$ an computes the $m \\times n$ matrix $B = cA$ by multiplying each entry of $A$ by $c$.  For example:\n",
    "$$\n",
    "c = 3, \\quad A = \\bm 1 & 2 \\\\ -1 & 0 \\em, \\quad cA = 3\\bm 1 & 2 \\\\ -1 & 0 \\em=\\bm 3 & 6 \\\\ -3 & 0\\em.\n",
    "$$\n",
    "In general, if $B = cA$, then $b_{ij}=ca_{ij}$ for each entry $i=1,\\dots,m$ and $j=1,\\dots,n$.\n",
    "\n",
    "[^notation]: Remember that we write $x \\in S$ to mean that the element $x$ lives in the set $S$.  In this example, $c \\in \\R$ means that the element $c$ lives in the real line $\\R$, and hence $c$ is a scalar.\n",
    "\n",
    "### Summary\n",
    "Using the definitions and properties above, it is not too hard, albeit a bit tedious, to show that the usual rules of algebra apply to sums and scalar multiples of matrices, as the following theorem shows.\n",
    "```{prf:theorem}\n",
    ":label: matalg-thm\n",
    "Let $A$, $B$, and $C$ be matrices of the same size, say $m \\times n$, and let $r$ and $s$ be scalars.  Then\\\n",
    "a. $A + B = B + A$\\\n",
    "b. $(A+B) + C = A + (B + C)$\\\n",
    "c. $A + 0 = A$\\\n",
    "d. $r(A+B) = rA + rB$\\\n",
    "e. $(r+s)A = rA + sA$\\\n",
    "f. $r(sA)=(rs)A$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866251b7-96fb-4b8c-b989-a756a17df879",
   "metadata": {},
   "source": [
    "## Matrix-vector multiplication\n",
    "A fundamental idea in linear algebra is to define the product of a matrix $A$ and a vector $\\vv x$ as a _linear combination_ of the columns of $A$ weighted by the coefficients in the vector $\\vv x$.[^matmul]  We use this as an opportunity to remind you of the definition of a linear combination of vectors, and then use it to define matrix-vector multiplication.  The idea of a linear combination is fundamental, and we will revisit it several times over the course of the semester from many different perspectives.\n",
    "\n",
    "[^matmul]: You may have seen other definitions of matrix-vector multiplication before, for example, based on the sum of products across rows.  This definition is equivalent to the one introduced in this section, but we will find it less convenient for our purposes.\n",
    "\n",
    "```{prf:definition} Linear Combinations of Vectors\n",
    ":label: lincombo\n",
    "Given a collection of $n \\times 1$ columng vectors $\\vv v_1, \\vv v_2, \\dots, \\vv v_p$ and a collection of scalars $c_1,c_2,\\dots, c_p$, the vector $\\vv y$ defined by\n",
    "$$\n",
    "\\vv y = c_1 \\vv v_1 + c_2 \\vv v_2 + \\cdots + c_p \\vv v_p\n",
    "$$\n",
    "is called a _linear combination_ of $\\vv v_1, \\vv v_2, \\dots, \\vv v_p$ with _weights_ $c_1,c_2,\\dots, c_p$.\n",
    "```\n",
    "\n",
    "The weights $c_i$ in a linear combination can be any real numbers, including zero.  For example, some linear combinations of $\\vv v_1$ and $\\vv v_2$ are\n",
    "$$\n",
    "\\pi \\vv v_1 + v_2, \\quad \\frac{1}{2}\\vv v_1 (=\\frac{1}{2}\\vv v_1 + 0 \\vv v_2), \\quad \\vv 0(=0\\vv v_1 + 0 \\vv v_2).\n",
    "$$\n",
    "\n",
    "```{prf:example} Linear Combinations of $2 \\times 1$ vectors\n",
    "TODO Example 4 in Ch 1.3 of ALA\n",
    "```\n",
    "\n",
    "With [](#lincombo) in hand, we introduce (a maybe new to you definition of) matrix-vector multiplication as a linear combination of the columns of a matrix.\n",
    "````{prf:definition} Matrix-Vector Multiplication\n",
    "If $A$ is an $m \\times n$ matrix, with columns $\\vv a_1, \\dots, \\vv a_n$, and if $\\vv x$ is a $n \\times 1$ vector, then the _product of $A$ and $\\vv x$_, denoted $A\\vv x$, is the [linear combination](#lincombo) of the columns of $A$ using the corresponding entries in $\\vv x$ as weights:\n",
    "```{math}\n",
    ":label: mat-vec\n",
    "A\\vv x = \\bm \\vv a_1 & \\vv a_2 & \\cdots & \\vv a_n\\em\\bm x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\\em = x_1 \\vv a_1 + x_2 \\vv a_2 + \\cdots \\vv x_n a_n.\n",
    "```\n",
    "Note that $A\\vv x$ is defined only if the number of columns of $A$ equals the number of entries in $\\vv x$.\n",
    "````\n",
    "\n",
    "```{prf:example} Some Matrix-Vector Products\n",
    "TODO\n",
    "````\n",
    "\n",
    "### Consequences on Systems of Linear Equations\n",
    "Our definition of $A\\vv x$ leads directly to the following very useful fact.\n",
    "```{important}\n",
    "The equation $A\\vv x = \\vv b$ has a solution if and only if $\\vv b$ is a linear combination of the colums of $A$.\n",
    "```\n",
    "When we introduce vector spaces in the next chapter, we will revisit this fact and see that it gives a very clear picture of the _geometry_ of systems of linear equations, and will allows us to answer questions like \"Given a matrix $A$, for what right hand sides $\\vv b$ does the equation $A\\vv x=\\vv b$ have a solution?\" and \"When does $A\\vv x = \\vv b$ have no solution? infinite solutions?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c11e7-4867-4019-a754-4a79436b5990",
   "metadata": {},
   "source": [
    "### Properties of the Matrix-Vector Product $A\\vv x$\n",
    "The facts in the next theorem are important, and will be used often throughout this semester.  The proof is straightforward, and relies on the definition of $A\\vv x$ and how we defined matrix addition and scalar multiplication above (remember that vectors are a special kind of matrix!).\n",
    "\n",
    "````{prf:theorem} Properties of $A \\vv x$\n",
    ":label: matvec-thm\n",
    "(matvec-linearity)=\n",
    "If $A$ is an $m \\times n$ matrix, $\\vv u$ and $\\vv v$ are $n \\times 1$ vectors, and $c$ is a scalar, then:\\\n",
    "a. $A(\\vv u + \\vv v) = A\\vv u + A\\vv v$\\\n",
    "b. $A(c \\vv u) = c(A \\vv u)$\n",
    "```{prf:proof} Proof of [](#matvec-thm)\n",
    ":class: dropdown\n",
    "To keep things simple, we take $n=3$ so that $A=\\bm \\vv a_1 & \\vv a_2 & \\vv a_3\\em$, and $\\vv u$ and $\\vv v$ are $3 \\times 1$ vectors.  The proof of the general case is similar.  For $i=1,2,3$ let $u_i$ and $v_i$ be the $i$th entries in $\\vv u$ and $\\vv v$, respectively, i.e., $\\vv u = (u_1, u_2, u_3)$ and $\\vv v = (v_1, v_2, v_3)$.  \n",
    "\n",
    "To prove statement (a), we compute $A(\\vv u + \\vv v)$ as a linear combination of the columns of $A$ using the entries in $\\vv u + \\vv v$ as weights:\n",
    "\\begin{eqnarray}\n",
    "A(\\vv u + \\vv v)&=\\bm \\vv a_1 & \\vv a_2 & \\vv a_3\\em\\bm u_1 + v_1 \\\\ u_2 + v_2 \\\\ u_3 + v_3 \\em \\\\\n",
    "& = (u_1 + v_1)\\vv a_1 + (u_2 + v_2)\\vv a_2 + (u_3 + v_3)\\vv a_3 \\\\\n",
    "& = (u_1\\vv a_1 + u_2 \\vv a_2 + u_3\\vv a_3) + (v_1\\vv a_1 + v_2 \\vv a_2 + v3\\vv a_3) \\\\\n",
    "& = A\\vv u + A\\vv v.\n",
    "\\end{eqnarray}\n",
    "To go from line 1 to 2, we used the definition of matrix-vector multiplication, taking a linear combination of the columns of $A$ weighted by the entries $(u_i + v_i)$ of $\\vv u + \\vv v$.  From line 2 to 3, we used the property that scalar multiplication is distributive to split apart the terms depending the $u_i$ from those depending on the $v_i$.  Finally, from line 3 to 4, we used the definition of matrix-vector multplication again to go from a linear combination of the columns of $A$ to matrix-vector products.\n",
    "\n",
    "to prove statement (b), we compute $A(c\\vv u)$ as a linear combination of the columns of $A$ using the entries in $c\\vv u$ as weights:\n",
    "\\begin{eqnarray}\n",
    "A(c\\vv u)&=\\bm \\vv a_1 & \\vv a_2 & \\vv a_3\\em\\bm cu_1 \\\\ cu_2 \\\\ cu_3 \\em \\\\\n",
    "& = c(u_1\\vv a_1) + c(u_2\\vv a_2) + c(u_3\\vv a_3) \\\\\n",
    "& = c(u_1 \\vv a_1 + u_2 \\vv a_2 + u_3\\vv a_3) \\\\\n",
    "& = c(A\\vv u).\n",
    "\\end{eqnarray}\n",
    "To go from line 1 to 2, we used the definition of matrix-vector multiplication, taking a linear combination of the columns of $A$ weighted by the entries $cu_i$ of $c\\vv u$.  From line 2 to 3, we used the property that scalar multiplication is distributive to factor out a $c$ from every term.  Finally, from line 3 to 4, we used the definition of matrix-vector multplication again to go from a linear combination of the columns of $A$ to matrix-vector products.\n",
    "```\n",
    "````\n",
    "\n",
    "#### A Geometric Perspective\n",
    "This perspective on matrix-vector products gives us a very geometric interpretation of what is going on.  Given a $n \\times 1$ vector $\\vv x$, an $m \\times n$ matrix $A$ maps $\\vv x$ to a $m \\times 1$ vector $A\\vv x$, i.e., the map[^mapsto] $\\vv x \\mapsto A\\vv x$ is function that transforms $n \\times 1$ vectors into $m \\times 1$ vectors.  We will revisit this idea in much greater detail in the next chapter on _vector spaces_, but this idea will help us gain some intuition about some of the rules of matrix-matrix multiplication that we will see shortly.\n",
    "\n",
    "[^mapsto]: The symbol $\\mapsto$ means ``maps to.''  So when we see $\\vv x \\mapsto A\\vv x$, this is mathematical notation for a function that takes in $\\vv x$ and maps it to $A\\vv x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d13037-9037-474b-85fd-ce97613e4a9f",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "When a matrix $B$ multiplies a vector $\\vv x$, it transforms $\\vv x$ into the vector $B \\vv x$.  If this vector is then multiplied in turn by a matrix $A$, the resulting vector is $A(B\\vv x)$.  We can think of the vector $A(B\\vv x)$ as being produced from $\\vv x$ by a _composition_ of mappings: first we apply the transformation $\\vv x \\mapsto B \\vv x$ to the vector $\\vv x$, and then we apply the transformation $\\vv y \\mapsto A \\vv y$ to the vector $\\vv y = B \\vv x$.  Our goal is to represent this composite mapping as multiplication by a single matrix, denoted by $AB$, so that\n",
    "\\begin{equation}\n",
    "\\label{matmul}\n",
    "A(B\\vv x) = (AB)\\vv x.\n",
    "\\end{equation}\n",
    "This idea is illustrated in [](#matmul-fig)\n",
    "\n",
    "```{figure} ../figures/02-matmul-AB.png\n",
    ":label: matmul-fig\n",
    ":alt: Multiplication by $B$ and then $A$ and multiplication by $AB$.\n",
    ":align: center\n",
    "\n",
    "Multiplication by $B$ and then $A$ and multiplication by $AB$. Figure 3 from Ch 2.1 of ALA.\n",
    "```\n",
    "Fortunately, we already have all of the tools we need to do this!  Suppose that $A$ is $m \\times n$, $B$ is $n \\times p$, and $\\vv x$ is a $p \\times 1$ vector.  Denote the columns of $B$ by $\\vv b_1,\\dots,\\vv b_p$ and the entries in $\\vv x$ by $x_1,\\dots, x_p$.  Then\n",
    "$$\n",
    "B\\vv x = x_1\\vv b_1 + \\cdots + x_p\\vv b_p.\n",
    "$$\n",
    "Now by the [linearity of multiplication by $A$](#matvec-linearity), we have\n",
    "\\begin{eqnarray}\n",
    "A(B\\vv x) &= A(x_1\\vv b_1) + \\cdots + A(x_p\\vv b_p) \\\\\n",
    "& = x_1A\\vv b_1 + \\cdots + x_pA\\vv b_p.\n",
    "\\end{eqnarray}\n",
    "We see that the vector $A(B\\vv x)$ is a linear combination of the vectors $A\\vv b_1,\\dots,A\\vv b_p$ weighted by the entries $x_1,\\dots,x_p$ of $\\vv x$.  We can rewrite this in matrix-vector notation as\n",
    "$$\n",
    "A(B\\vv x) = \\bm A\\vv b_1 & A\\vv b_2 & \\cdots & A\\vv b_p\\em \\vv x.\n",
    "$$\n",
    "Therefore multiplying $\\vv x$ by $\\bm A\\vv b_1 & A\\vv b_2 & \\cdots & A\\vv b_p\\em$ directly transforms $\\vv x4 into $A(B\\vv x)$: we found the matrix we were looking for!\n",
    "```{prf:definition}\n",
    "If A is an $m \\times n$ matrix, and if $B$ is an $n \\times p$ matrix with columns $\\vv b_1,\\dots,\\vv b_p$, then the matrix product $AB$ is then the $m \\times p$ matrix whose columns are $A\\vv b_1, A\\vv b_2,\\dots, A\\vv b_p$, that is,\n",
    "$$\n",
    "AB = A\\bm \\vv b_1 & \\vv b_2 & \\cdots & \\vv b_p\\em = \\bm A\\vv b_1 & A\\vv b_2 & \\cdots & A\\vv b_p\\em.\n",
    "$$\n",
    "```\n",
    "This definition makes equation [](#matmul) true for all possible $p \\times 1$ vectors $\\vv x$ and also helps us understand that _multiplication of matrices corresponds to a composition of transformations_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ccb20b-ec41-4442-815d-d3fdc842332e",
   "metadata": {},
   "source": [
    ":::{prf:example}  TODO: Example of Computing\n",
    ":label: matmul-example\n",
    "write me\n",
    ":::\n",
    "\n",
    "````{exercise}  TODO: Exercise testing size of $AB$ and $BA$\n",
    ":label: matmul-ex1\n",
    "Write me:\n",
    ":::{hint} Click me for a hint!\n",
    ":class: dropdown\n",
    "Write me\n",
    "\n",
    ":::\n",
    "```{solution} my-exercise\n",
    ":class: dropdown\n",
    "Write me\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd6ca0-7ffe-4642-ab6b-bd23f41b748b",
   "metadata": {},
   "source": [
    "### Properties of Matrix Multiplication\n",
    "We use $I_m$ to denote the $m \\times m$ identity matrix.\n",
    "```{prf:definition}\n",
    ":label: identity\n",
    "The _identity matrix $I_m$_ is the $m \\times m$ matrix\n",
    "$$\n",
    "I_m = \\bm \n",
    "1 & 0 & 0 & \\cdots & 0 & 0 \\\\\n",
    "0 & 1 & 0 & \\cdots & 0 & 0 \\\\\n",
    "0 & 0 & 1 & \\cdots & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\cdots & 1 & 0 \\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 1\n",
    "\\em.\n",
    "$$\n",
    "The entries along the _main diagonal_, which runs from top left to bottom right, are equal to 1, and all other entries are equal to 0.  The identify matrix satisfies $I_m \\vv x = \\vv x$ for all $m \\times 1$ vectors $\\vv x$.\n",
    "```\n",
    "\n",
    "The following theorem lists standard properties of matrix multiplication. \n",
    "```{prf:theorem} Matrix Multiplication Properties\n",
    ":label: matmul-thm\n",
    "Let $A$ be an $m \\times n$, and let $B$ and $C$ have sizes for which the indicated sums and products are defined.  Then\\\n",
    "\\begin{equation}\n",
    "\\begin{array}{ll}\n",
    "\\text{a. } A(BC)=(AB)C & \\text{(associative law of multiplication)}\\\\\n",
    "\\text{b. } A(B+C)=AB + AC &\\text{(left distributive law)}\\\\\n",
    "\\text{c. } (B+C)A=BA + CA &\\text{(right distributive law)}\\\\\n",
    "\\text{d. } r(AB)=A(rB) &\\text{for any scalar $r$} \\\\\n",
    "\\text{e. } I_mA=A=AI_n &\\text{(identity for matrix multiplication)} \\\\\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "```\n",
    "We omit the proof of this theorem, but comment on some of its implications.  The associative and distributive laws of [](#matalg-thm) and [](#matmul-thm)tell us that pairs of parentheses in matrix expressions can be inserted and deleted in the same way as in algebra for ordinary numbers.  This is why we will usually write $ABC$ for the product that can be computed as either $A(BC)$ or $(AB)C$: it does not matter how we group the matrices when computing the product, so long as the left-to-right order of the matrices is preserved.\n",
    "\n",
    "```{warning} Matrix Multiplication is *NOT* Commutative\n",
    "The left-to-right order in matrix products is critical because $AB$ and $BA$ are usually not the same.  In fact, unless $A$ and $B$ are both square matrices, only one of $AB$ or $BA$ will even be defined.  Given what we've seen so far, this shouldn't be surprising: the columns of $AB$ are linear combinations of the columns of $A$, whereas the columns of $BA$ are constructed from the columns of $B$.  We emphasize the position of the factors in the product $AB$ by saying $A$ is _right-multiplied_ by $B$ or that $B$ is _left-multiplied_ by $A$.  If $AB=BA$, we say that $A$ and $B$ _commute_ with each other.\n",
    "```\n",
    "\n",
    "```{prf:example} TODO: mat-mul commute/don't commute\n",
    "write me\n",
    "```\n",
    "\n",
    "```{warning} Cancellation Laws *DO NOT* hold\n",
    "If $AB = AC$, then it is _not_ true in genereal that $B=C$\n",
    "```\n",
    "```{warning} $AB=0$\n",
    "If the product $AB$ is the zero matrix, you _cannot_ conclude in general that either $A=0$ or $B=0$.\n",
    "```\n",
    "We will get a better understanding for why these properties that hold for scalar multiplication breakdown for matrix multiplication later, but for now, it is still important that you are aware of these quirks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac70c4-7f56-449e-ab46-1d277f149989",
   "metadata": {},
   "source": [
    "## Block Matrices and Vectors\n",
    "TODO: adapt from VMLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65622db4-83b8-4b54-b039-dc04514a5d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
