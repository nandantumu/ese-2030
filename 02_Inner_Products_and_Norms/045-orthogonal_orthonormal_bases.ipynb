{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Orthogonal and Orthonormal Bases\n",
    "subject: Inner Products and Norms\n",
    "subtitle: \n",
    "short_title: Orthogonal and Orthonormal Bases\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: Orthogonal Basis, Orthonormal Basis\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in ALA 4.1.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- What is an orthogonal basis?\n",
    "- What is an orthonormal basis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal and Orthonormal Bases\n",
    "\n",
    "Let $V$ be an [inner product space](#inner-product-space-defn) (as usual, we will assume that the scalars over which $V$ is defined are real valued). Remember that $\\vv v, \\vv w \\in V$ are [orthogonal](#orthogonal-defn) if $\\langle \\vv v, \\vv w\\rangle = 0$. If $\\vv v, \\vv w \\in \\mathbb{R}^n$ and $\\langle \\vv v, \\vv w\\rangle = \\vv v \\cdot \\vv w$ is the dot product, this simply means that $\\vv v$ and $\\vv w$ are perpendicular (meet at a right angle).\n",
    "\n",
    "Orthogonal vectors are useful, because they point in completely different directions, making them particularly well-suited for defining bases. Orthogonal vectors give rise to the concept of an *orthogonal basis*.\n",
    "\n",
    ":::{prf:definition} Orthogonal Basis\n",
    ":label: orthogonal-basis-defn\n",
    "\n",
    "A [basis](#basis_defn) $\\vv{b_1}, ..., \\vv{b_n}$ of an $n$-dimensional inner product space $V$ is called *orthogonal* if $\\langle \\vv{b_i}, \\vv{b_j}\\rangle = 0$ for all $i\\neq j$. In this case, the collection $\\vv{b_i}$ are said to be *mutually orthogonal*, i.e., every pair of distinct vectors are [orthogonal](#orthogonal-defn).\n",
    ":::\n",
    "\n",
    "If each basis vector in an orthogonal basis is a unit vector (has norm equal to one), then they form a special type of orthogonal basis known as an *orthonormal basis.*\n",
    "\n",
    ":::{prf:definition} Orthonormal Basis\n",
    ":label: orthonormal-basis-defn\n",
    "\n",
    "An [orthogonal basis](#orthogonal-basis-defn) $\\vv{b_1}, ..., \\vv{b_n}$ of an $n$-dimensional inner product space $V$ is called *orthonormal* if $\\|\\vv{b_i}\\| = 1$ for each $i$. Here, $\\|\\vv v\\| = \\sqrt{\\langle \\vv v, \\vv v\\rangle}$ is the norm induced by the inner product.\n",
    ":::\n",
    "\n",
    "A simply way to construct an orthonormal basis from an orthogonal basis is to *normalize* each of its elements, that is, to replace each basis element $\\vv{b_i}$ with its normalized counterpart $\\frac{\\vv{b_i}}{\\|\\vv{b_i}\\|}$. As an exercise, can you formally verify that $\\frac{\\vv{b_1}}{\\|\\vv{b_1}\\|}, ..., \\frac{\\vv{b_n}}{\\|\\vv{b_n}\\|}$ is an orthonormal basis for if $\\vv{b_1}, ..., \\vv{b_n}$ is an orthogonal one? Can you explain why rescaling each entry does not affect the mutual orthogonality of this set?\n",
    "\n",
    "```{note}\n",
    "A very useful property of a collection of mutually orthogonal vectors is that they are automatically linearly independent. In particular, if $\\vv{v_1}, ..., \\vv{v_k}$ satisfy $\\langle \\vv{v_i}, \\vv{v_j} \\rangle = 0$ for all $i \\neq j$ (and $\\vv{v_i} \\neq 0$ for all $i$), then they are [linearly independent](#lin_dep).\n",
    "\n",
    "To see this, we take an arbitrary linear combination of the $\\vv{v_i}$ and set it to $0$:\n",
    "\n",
    "\\begin{align*}\n",
    "    c_1 \\vv{v_1} + c_2\\vv{v_2} + ... + c_k\\vv{v_k} = \\vv 0\\label{expr:lincomboequation}\n",
    "\\end{align*}\n",
    "\n",
    "Let's take the inner product of both sides of this equation with any $\\vv{v_i}$:\n",
    "\n",
    "\\begin{align*}\n",
    "0 = \\langle \\vv 0, \\vv{v_i} \\rangle &= \\langle c_1\\vv{v_1} + c_2\\vv{v_2} + ... + c_k\\vv{v_k}, \\vv{v_i}\\rangle\\\\\n",
    "&= c_1\\langle \\vv{v_1}, \\vv{v_i} \\rangle + ... + c_i\\langle \\vv{v_i}, \\vv{v_i} \\rangle + ... + c_k\\langle \\vv{v_k}, \\vv{v_i} \\rangle \\quad \\text{(linearity of $\\langle \\cdot, \\vv{v_i}\\rangle$)}\\\\\n",
    "&= c_i\\langle \\vv{v_i}, \\vv{v_i}\\rangle = c_i \\|\\vv{v_i}\\|^2 \\quad\\text{(orthogonality)}\n",
    "\\end{align*}\n",
    "\n",
    "Since $\\vv{v_i} \\neq 0$, $\\|\\vv{v_i}\\|^2 > 0$, which means $c_i = 0$. We can repeat this game with all $\\vv{v_i}$ for $i = 1, ..., k$, to conclude that [](#expr:lincomboequation) holds only if $c_1 = c_2 = ... = c_k = 0$. Hence, the mutually orthogonal collection $\\vv{v_1}, ..., \\vv{v_k}$ is linearly independent.\n",
    "\n",
    "```\n",
    "\n",
    ":::{prf:example} The standard basis for $\\mathbb{R}^n$\n",
    ":label: standard-basis-ex\n",
    "\n",
    "A familiar example of an orthonormal basis for $\\mathbb{R}^n$ equipped with the standard inner product is the collection of standard basis elements:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\vv{e_1} = \\bm 1 \\\\ 0 \\\\ \\vdots \\\\ 0\\em, \\quad\\vv{e_2} = \\bm 0 \\\\ 1 \\\\ \\vdots \\\\ 0\\em,\\quad ...,\\quad \\vv{e_n} = \\bm 0 \\\\ 0 \\\\ \\vdots \\\\ 1\\em\n",
    "\\end{align*}\n",
    "\n",
    "This is known as the *standard basis* of $\\mathbb{R}^n$.\n",
    ":::\n",
    "\n",
    ":::{prf:example} Normalizing an orthogonal basis\n",
    ":label: normalizing-ex\n",
    "\n",
    "The vectors\n",
    "\n",
    "\\begin{align*}\n",
    "    \\vv{b_1} = \\bm 1 \\\\2 \\\\ -1\\em, \\quad \\vv{b_2} = \\bm 0\\\\1\\\\2\\em, \\quad \\vv{b_3} = \\bm 5\\\\-2\\\\1\\em\n",
    "\\end{align*}\n",
    "\n",
    "are an orthogonal basis for $\\mathbb{R}^3$. One easy way to check this is to confirm that $\\vv{v_i} \\cdot \\vv{b_j} = 0$ for all $i\\neq j$ (this is indeed true). Since $\\text{dim} (\\mathbb{R}^3) = 3$, and $\\vv{b_1}, \\vv{b_2}, \\vv{b_3}$ are linearly independent, they must be a basis.\n",
    "\n",
    "To turn them from an orthogonal basis into an orthonormal basis, we simply divide every vector by its length to obtain\n",
    "\n",
    "\\begin{align*}\n",
    "    \\vv{v_1} = \\frac{\\vv{b_1}}{\\|\\vv{b_1}\\|} = \\frac{1}{\\sqrt 6}\\bm 1\\\\2\\\\-1\\em, \\quad \\vv{v_2} = \\frac{\\vv{b_2}}{\\|\\vv{b_2}\\|} = \\frac{1}{\\sqrt 5}\\bm 0\\\\1\\\\2\\em,\n",
    "    \\quad \\vv{v_3} = \\frac{\\vv{b_3}}{\\|\\vv{b_3}\\|} = \\frac{1}{\\sqrt{30}}\\bm 5\\\\-2\\\\1\\em\n",
    "\\end{align*}\n",
    "\n",
    "This example highlights a more general principle, which is again quite useful: if $\\vv{v_1}, ..., \\vv{v_n}$ are mutually orthogonal, then they form a basis for their [span](#ln_comb) $W = \\text{span}\\{ {v_1}, ..., \\vv{v_n} \\} \\subseteq V$, which is thus a [subspace](#sub_def) fo $\\text{dim}(W) = n$. It then follows that if $\\text{dim}(V) = n$, then $\\vv{v_1}, ..., \\vv{v_n}$ are an orthogonal basis for $V$ (this is precisely the observation we used in this example).\n",
    ":::\n",
    "\n",
    "# Working in Orthogonal Bases\n",
    "\n",
    "So why do we care about orthogonal (or even better, orthonormal) bases? Turns out they make a lot of the computations that we've been doign so far MUCH easier.\n",
    "\n",
    "We'll start with some important properties of computing a vector's coordinates with respect to an orthogonal basis.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
